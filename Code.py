# -*- coding: utf-8 -*-
"""profit_value_Internship.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19Ipae2A_ztM6_Y9FVbBeer2tNqErgnWx
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import sklearn

df = pd.read_csv('/content/drive/MyDrive/profit project/50_Startups.csv')
print(df.head())

print(df.shape[0],df.shape[1]) #rows and columns

df.info() #datatypes

df.isnull().sum() #null_check

print(df.duplicated().sum()) #duplicate values

df.describe()

corr = df.corr()
corr

sns.heatmap(df.corr(), annot=True)
plt.show()

x = df['R&D Spend']  #x assign to all column except profit
a = df.drop(['Administration', 'Profit'], axis=1)
b = df.drop(['Profit'], axis=1)

b.head()

y = df['Profit'] #y assign to profit

y.head()

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,random_state=0) #splitdata

from sklearn.model_selection import train_test_split
a_train,a_test,y_train,y_test=train_test_split(a,y,test_size=0.30,random_state=0) #splitdata

from sklearn.model_selection import train_test_split
b_train,b_test,y_train,y_test=train_test_split(b,y,test_size=0.30,random_state=0) #splitdata

"""**Linear Regression**"""

x_train_array = np.array(x_train).reshape(-1,1)

from sklearn.linear_model import LinearRegression
lg = LinearRegression()
lg2 = LinearRegression()
lg3 = LinearRegression()

lg.fit(x_train_array,y_train) #train model
lg2.fit(a_train,y_train)
lg3.fit(b_train,y_train)

x_test_array = np.array(x_test).reshape(-1,1)

y_pred = lg.predict(x_test_array)
a_pred = lg2.predict(a_test)
b_pred = lg3.predict(b_test)

lg.score(x_test_array, y_test)

lg2.score(a_test, y_test)

lg3.score(b_test, y_test)

plt.scatter(x_test_array, y_test, color ='b')
plt.plot(x_test_array, y_pred, color ='k')
plt.title('Linear Regression')
plt.xlabel('R&D spend')
plt.ylabel('Profit')
  
plt.show()
# Data scatter of predicted values

"""**Polynomial Regression**"""

from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(3)
poly2 = PolynomialFeatures(3)
poly3 = PolynomialFeatures(3)
x_poly = poly.fit_transform(x_train_array)
a_poly = poly.fit_transform(a_train)
b_poly = poly.fit_transform(b_train)
  
poly.fit(x_poly, y_train)
poly2.fit(a_poly, y_train)
poly3.fit(b_poly, y_train)

lin = LinearRegression()
lin2 = LinearRegression()
lin3= LinearRegression()

lin.fit(x_poly, y_train)
lin2.fit(a_poly, y_train)
lin3.fit(b_poly, y_train)

lin.score(x_poly, y_train)

lin2.score(a_poly, y_train)

lin3.score(b_poly, y_train)

# Visualising the Polynomial Regression results
plt.scatter(x_test_array, y_test, color = 'blue')
  
plt.plot(x_test_array, lin.predict(poly.fit_transform(x_test_array)), color = 'red')
plt.title('Polynomial Regression')
plt.xlabel('R&D spend')
plt.ylabel('Profit')
  
plt.show()

"""**Random Forest Regression**"""

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor(random_state = 0)
rf2 = RandomForestRegressor(random_state = 0)
rf3 = RandomForestRegressor(random_state = 0)

rf.fit(x_train_array,y_train)
rf2.fit(a_train,y_train)
rf3.fit(b_train,y_train)

rf.score(x_test_array,y_test)

rf2.score(a_test,y_test)

rf3.score(b_test,y_test)

r_pred = rf.predict(x_test_array)

plt.scatter(x_test_array, y_test, color ='b')
plt.plot(x_test_array, r_pred, color ='k')
plt.title('Random Forest Regression')
plt.xlabel('R&D spend')
plt.ylabel('Profit')

"""**End**"""